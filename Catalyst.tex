\section{Catalyst}
\label{sec:Catalyst}

Although it is straightforward for a simulation development team to add some
basic \vda capabilities into simulation code, our desire is to have a
general-purpose fully-featured library that leverages existing
implementations.  The intention is threefold.  First, by leveraging existing
\vda libraries we can benefit from the accumulation of over two decades of
visualization research and development.  Second, by making the library
general purpose we can quickly apply our \insitu \vda capabilities to many
simulations as opposed to a single simulation.  Third, by using our
existing code we can integrate the \insitu tools with our traditional
post-processing tools both to provide interfaces that users are already
familiar and comfortable with and to apply scalable algorithms designed for
\insitu with our post-processing tools and vice versa.

Catalyst is a C++ library with an externally facing API to C, FORTRAN, and
Python.  It is built atop the Visualization Toolkit (VTK)\lcite{VTK} and
ParaView\lcite{ParaView}.  By building Catalyst with VTK, it can access a
large number of algorithms including writers for I/O, rendering algorithms,
and processing algorithms such as isosurface extraction, slicing, and flow
particle tracking.  Catalyst uses ParaView to implement and manage the
\vda, which is defined using a visualization
pipeline\lcite{Moreland2013:TVCG}.  Although it is possible to construct
pipelines entirely in C++, the ParaView control structure allows pipelines
configured through Python scripts.

\begin{figure}[htb]
  \centering
  \includegraphics{figures/CatalystCoupling}
  \caption{Coupling a simulation with Catalyst.}
  \label{fig:CatalystCoupling}
\end{figure}

\subsection{Catalyst Architecture}

Catalyst boils the ParaView and VTK architecture down into five API calls that
manage all the processing required for operating a processing pipeline.
Initialize and Finalize are expected calls when dealing with MPI; this is where
Catalyst will first access MPI World.  RequestDataDescription and CoProcess
handle the hand-shake from the simulation code to Catalyst.
RequestDataDescription passed current time information to Catalyst, and
Catalyst passes back whether or not it should process and which fields it
needs.  This may allow the simulation code, through the adaptor described
below, to efficiently pass only what is necessary at that time.  The CoProcess
call is where control is passed to Catalyst for processing.  This call will
hang until Catalyst finishes and returns control to the simulation.

The AddPipeline call is where a majority of the work is done.  Although there
is usually only one pipeline object passed to Catalyst, it is possible to pass
several.  It is also common for this pipeline object to be written in Python
because this is the native scripting language for ParaView, but it is possible
for the pipeline to be hard coded C++.  While there is some overhead cost to
using Python code in the pipeline here, it is very low due to its nature as a
glue code combining the C++ filters which are written in VTK.  The advantage is
that the scripted pipeline can change to access any feature available in
Catalyst while only compiling the capability once.

\begin{figure}[htb]
  \centering
  \includegraphics{figures/ScriptExport}
  \caption{Wizard plugin within ParaView to export interactive traces as 
Catalyst pipelines for use within a coupled simulation.}
  \label{fig:ScriptExport}
\end{figure}

In addition to the advantages of writing Python pipeline scripts by hand, there
is a well supported plugin for ParaView that will automatically create Catalyst
Python scripts automatically from within the GUI, based on traces of user
interaction with the GUI, Figure~\ref{fig:ScriptExport}.  This plugin works by
replacing a file read at the top of the pipeline with the same VTK data object
provided by the adaptor (described below).  From the perspective of the
pipeline it could be operating on data being read from a file, but this data is
coming from an in-memory \insitu transfer.  The plugin will examine all views
currently open within the ParaView view and create equivalent views with
independent image sizes in the script.  It is also possible to make place-holder
objects within the pipeline to act as file write points.  Usually these will be
placed at the end of a long chain of processing to store the resulting
processed data, but it is also possible to splice these file writes earler in
the pipeline to see the effects of different stages of processing.  Each file
and image writer can write at an independent frequency, allowing for very
infrequent writes of potentially large files while also allowing for more
frequent small image writes as the simulation proceeds.

\subsection{Simulation Adaptor}

Since Catalyst will extend to a variety of existing simulation codes, our
design does not expect its API to easily and efficiently process internal
structures in all possible codes directly.  Our solution is to rely on
adapters --- which are small pieces of code written for each new linked
simulation --- to translate data structures between the simulation's code
(for our use case the CTH shock physics code) and Catalyst's VTK-based
architecture, as shown in Figure~\ref{fig:CatalystCoupling}.  The adapter
must also establish a mechanism that allows the simulation to define a
visualization pipeline and periodically invoke the analysis while running
the simulation, which in our CTH adapter we control through the CTH input
deck.

To conserve memory, our adapter directly interfaces the \vda code to the
data structures defined by CTH.  This interface is challenging because
although the blocks of data are represented sequentially in both CTH and
VTK, the multidimensional order is different.  To address this, our adapter
contains an interface wrapper above the standard VTK array.  The wrapper
reimplements the array's accessor functions to handle the order difference
between the two systems.  Although there is a minor overhead in additional
pointer arithmetic and virtual method calls, it saves us from a deep memory
copy.

\subsection{References}

The Catalyst library and the algorithms we use within CTH are an
accumulation of several years work, starting with the development of
fragment analysis algorithms with our post-processing
tools\lcite{Moreland2008:UltraVis,Ice2009,Moreland2010}, described in more
detail in Section~\ref{sec:UseCase}.  Subsequent work lead to the
development of Catalyst\lcite{Fabian2011} and the scaling of algorithms
used in conjunction with CTH\lcite{Fabian2012}.
