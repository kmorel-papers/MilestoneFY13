\section{Catalyst}
\label{sec:Catalyst}

Catalyst is a general purpose, full-featured library that leverages existing
implementations of analysis and visualization capabilities.
The intent in doing this is threefold.  First, by leveraging existing
\vda libraries we can benefit from the accumulation of over two decades of
visualization research and development.  Second, by making the library general
purpose we can quickly apply our \insitu \vda capabilities to many simulations
as opposed to a single simulation.  Third, by using our existing code we can
integrate the \insitu tools with our traditional post-processing tools to
provide interfaces that users are already familiar and comfortable with and to
apply scalable algorithms designed for \insitu with our post-processing tools.


Catalyst is a C++ library with an API available in C, FORTRAN, and
Python.  It is built atop the Visualization Toolkit (VTK)\lcite{VTK} and
ParaView\lcite{ParaView}.  This means that Catalyst takes advantage of a
large number of algorithms including writers for I/O, rendering algorithms,
and processing algorithms such as isosurface extraction, slicing, and flow
particle tracking.  Catalyst uses ParaView to implement and manage the
\vda, which is defined using a visualization
pipeline\lcite{Moreland2013:TVCG}.  Although it is possible to construct
pipelines entirely in C++, a more flexible approach is defining pipelines 
with Python scripts.

\begin{figure}[htb]
  \centering
  \includegraphics{figures/CatalystCoupling}
  \caption{Coupling a simulation with Catalyst.}
  \label{fig:CatalystCoupling}
\end{figure}

\subsection{Catalyst Architecture}

Catalyst boils the ParaView and VTK architecture down into five API calls that
manage all the processing required for operating a processing pipeline.
Initialize and Finalize are expected calls when dealing with MPI; this is where
Catalyst will first access MPI World.  RequestDataDescription and CoProcess
handle the hand-shake from the simulation code to Catalyst.
RequestDataDescription passed current time information to Catalyst, and
Catalyst passes back whether or not it should process and which fields it
needs.  This may allow the simulation code, through the adaptor described
below, to efficiently pass only what is necessary at that time.  The CoProcess
call is where control is passed to Catalyst for processing.  This call will
hang until Catalyst finishes and returns control to the simulation.

The AddPipeline call is where a majority of the work is done.  Although there
is usually only one pipeline added to Catalyst, it is possible to add several.
It is also common for this pipeline to be written in Python, because this is
the native scripting language for ParaView.  It is also possible for the
pipeline to be coded in C++.  While there is overhead cost to using
Python code in the pipeline here, it is very low due to its nature as a glue
code combining the C++ filters which are written in VTK.  The advantage to
using Python is that a scripted pipeline can change alongside the simulation
input deck without needing to recompile.

\begin{figure}[htb]
  \centering
  \includegraphics{figures/ScriptExport}
  \caption{Wizard plugin within ParaView to export interactive traces as 
Catalyst pipelines for use within a coupled simulation.}
  \label{fig:ScriptExport}
\end{figure}

In addition to the advantages of writing Python pipeline scripts by hand, there
is a well supported plugin for ParaView that will automatically create Catalyst
Python scripts automatically from within the GUI, based on what the user
does interactively, as shown in Figure~\ref{fig:ScriptExport}.  This plugin 
reads in a file and creates the same code 
object provided by the adaptor (see Section~\ref{sec:Adaptor}).  The rest of the
pipeline operates identically whether the data has been read in from a file
or it is coming from an in-memory \insitu transfer.  

The plugin creates images for each view open at the time the script is 
exported. 
To write files, one can create objects
within the pipeline that act as file write points.  In general, these are 
placed
at the end of a long chain of processing to store the resulting processed data,
but it is also possible to splice these file writes into in the pipeline at
any point, so that intermediate data can be preserved. 
Each file and image writer
can write at an independent frequency, so that the output can be tuned 
precisely by the analyst.  For example, images (which tend to be very small) 
can be written out frequently, while large, detailed data files can be written out 
infrequently.

\subsection{Simulation Adaptor}\label{sec:Adaptor}

Since Catalyst will extend to a variety of existing simulation codes, our
design does not expect its API to easily and efficiently process internal
structures in all possible codes directly.  Our solution is to rely on
adapters --- which are small pieces of code written for each new linked
simulation --- to translate data structures between the simulation's code
(for our use case the CTH shock physics code) and Catalyst's VTK-based
architecture, as shown in Figure~\ref{fig:CatalystCoupling}.  The adapter
must also establish a mechanism that allows the simulation to define a
visualization pipeline and periodically invoke the data analysis while running
the simulation, which in our CTH adapter we control through the CTH input
deck.

To conserve memory, our adapter directly interfaces the \vda code to the
data structures defined by CTH.  This interface is challenging because
although the blocks of data are represented sequentially in both CTH and
VTK, the multidimensional order is different.  To address this, our adapter
contains an interface wrapper above the standard VTK array.  The wrapper
reimplements the array's accessor functions to handle the order difference
between the two systems.  Although there is a minor overhead in additional
pointer arithmetic and virtual method calls, it saves us from a deep memory
copy.

\subsection{References}

The Catalyst library and the algorithms we use within CTH are an
accumulation of several years work, starting with the development of
fragment analysis algorithms with our post-processing
tools\lcite{Moreland2008:UltraVis,Ice2009,Moreland2010}, described in more
detail in Section~\ref{sec:UseCase}.  Subsequent work lead to the
development of Catalyst\lcite{Fabian2011} and the scaling of algorithms
used in conjunction with CTH\lcite{Fabian2012}.
