
Each platform has directories for scaling experiments with cth 101_pipebomb problem:


   - pipe-null:  CTH, no analysis

   - pipe-pv:  CTH, in-situ analysis

   - pipe-nssi-null: CTH, in-transit (no analysis)
      - Measures overhead of transferring data to servers

   - pipe-nssi-pv: CTH, in-transit analysis
      - Move data to servers, perform analysis on servers


Problem Size : 
   - Levels=1
   - Levels=2
   - Levels=3 :      1,146 -- 1, 2, 4, 8, 16, 32  (1 server node)
   - Levels=4 :      5,080 -- 16, 32, 64, 128 (1 server node, )
   - Levels=5 :     33,094 -- 128, 256, 512, 1024 (2 server nodes, dt=2.02e-07)
   - Levels=6 :    218,510 -- 1024, 2048, 4096, 8192 (16 server nodes, dt=9.6e-08)
   - Levels=7 :  1,498,866 -- 4096, 8192, 16384, 32768 (100 server nodes, dt=4.556e-08)
   - Levels=8 : 10,728,933 -- 32K, 64K (670 server nodes)

   - Constants: 
      - Block Dims: Nx=10, Ny=10, Nz=10, NCFields=32, NMFields=6, NMaterials=8
      - Block Size: NCFields*Nx*Ny*Nz (cell data) + NMFields*NMaterials*Nx*Ny*Nz (mat data) = 640 kib

Measurements and Metrics :
  - Total run time (includes start up time for viz and cth as well as cycle timings)

  - pvspy_viz time per 10-cycles: 
      - For in-situ, this is the total time to perform the analysis.
      - For in-transit, this is the time to sync the metadata and data + time to wait for previous viz to complete. 
          - measured values:  sync metadata, sync data, wait

      plot 1: total time on the client (single plot with errorbars -- should show a cross-over point for unoptimized)
         - in-situ:  CTH + viz (tuned and untuned)
         - in-transit: CTH + xfer + wait (untuned)
  
      plot 2: breakdown of total timings (two stacked barcharts -- should show where inefficiencies lie)
         - in-situ (untuned):  CTH + viz
         - in-situ (tuned):  CTH + viz   -- should show the improved algorithm differences
         - in-transit: CTH + sync_data + sync_md + wait

      plot 3: processing rate  (blocks/sec) (line plot) -- this should increase as cores increase, flat means it doesn't scale
         - 10 cycles of CTH 
         - in-situ pvspy_viz (untuned)
         - in-situ pvspy_viz (tuned)
         - in-transit sync_data, sync_md, wait

  - Memory overheads
     - Without PV, with PV (before and during analysis), with nessie
     - trace with memory usage
 
  - Memory constraints (blocks/node)
     - This will tell us how many service nodes we need to process a given problem size
     - Based on runs that fail, it looks like a service node can manage ~16K blocks.  That is, 
       -- nodes = cores * maxb / 16K.  
     - I would like to make this more precise.   We don't know exactly how much memory ParaView uses. 

  - Scaling constraints for in-transit (blocks/sec/core)  
     - Per core value of the number of blocks the pvspy_viz function can process in a second. 
       This will help us calculate how many server nodes we need to keep up with the client.  
    - One thing that is a little odd about the in-situ runs is that it looks like the time it takes to 
       run the AMR analysis is not dependent on the number of cores.   A large portion must
       be serialized.  
    - Plots that look at 2, 4, 8 cores/node for service

Other considerations:  
   - The in-situ runs perform analysis every 10 cycles.   With in-transit, we could run analysis any time.  One thing
     we could do is check the status of the server.  If it is idle, perform analysis.  If not, continue with CTH.






